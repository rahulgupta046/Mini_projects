{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4790ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a585a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137616f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define emoji dictionary used\n",
    "emoji_dictionary = {\"0\" : \"\\u2764\\uFE0F\",\n",
    "                    \"1\" : \":baseball:\",\n",
    "                    \"2\" : \":grinning_face_with_big_eyes:\",\n",
    "                    \"3\" : \":disappointed_face:\",\n",
    "                    \"4\" : \":fork_and_knife:\"\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975157a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary:\n",
    "    print(emoji.emojize(emoji_dictionary[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb946f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x(path):\n",
    "    f = open(path)\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    text = text.replace(\"' \" , \"',\")\n",
    "    text = text.replace(\"\\n\", ',')\n",
    "    sep = text.split(\",\")\n",
    "    for i,sent in enumerate(sep):\n",
    "        sep[i] = sent.replace(\"'\", \"\")\n",
    "        sep[i] = sep[i].split()\n",
    "    x = np.array(sep)\n",
    "    return x\n",
    "\n",
    "def process_y(path):\n",
    "    f = open(path)\n",
    "    y = f.read()\n",
    "    f.close()\n",
    "    y = y.split(\" \")\n",
    "    y_ = []\n",
    "    for i, yval in enumerate(y):\n",
    "        y[i] = yval.replace(\"\\n\", \"\")\n",
    "        y_.append(y[i])\n",
    "    return np.array(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23117499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'emojify_train_x.csv'\n",
    "Y_TRAIN_PATH = 'Emojify_Y_train.csv'\n",
    "X_TEST_PATH =  'emojiy_test_x.csv'\n",
    "Y_TEST_PATH =  'emojiy_y_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343d3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\anaconda3\\envs\\gpu1\\lib\\site-packages\\ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "x_train = process_x(X_TRAIN_PATH)\n",
    "y_train = process_y(Y_TRAIN_PATH)\n",
    "\n",
    "x_test = process_x(X_TEST_PATH)\n",
    "y_test = process_y(Y_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f19c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['never', 'talk', 'to', 'me', 'again']),\n",
       "       list(['I', 'am', 'proud', 'of', 'your', 'achievements']),\n",
       "       list(['It', 'is', 'the', 'worst', 'day', 'in', 'my', 'life']),\n",
       "       list(['Miss', 'you', 'so', 'much']), list(['food', 'is', 'life'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56bca934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] üòû\n",
      "['I', 'am', 'proud', 'of', 'your', 'achievements'] üòÉ\n",
      "['It', 'is', 'the', 'worst', 'day', 'in', 'my', 'life'] üòû\n",
      "['Miss', 'you', 'so', 'much'] ‚ù§Ô∏è\n",
      "['food', 'is', 'life'] üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(x_train[i], emoji.emojize(emoji_dictionary[y_train[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0980dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb2cb856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word embeddings \n",
    "\n",
    "f = open('glove.6B.50d.txt', encoding = 'utf-8')\n",
    "embeddings = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float')\n",
    "    embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9437d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sentence to word vectors and create 3d tensor input for rnn\n",
    "#length of word vectors to form tensor\n",
    "emb_dim = list(embeddings.values())[0].shape[0]\n",
    "\n",
    "def embedding_output(x):\n",
    "    maxLen = 10\n",
    "    embedding_out = np.zeros((x.shape[0], maxLen, emb_dim))\n",
    "    \n",
    "    #iterate over sentences\n",
    "    for ix in range(x.shape[0]):\n",
    "        \n",
    "        #iterate over list of words for every sentence\n",
    "        for ij in range(len(x[ix])):\n",
    "            try:\n",
    "                embedding_out [ix][ij] = embeddings[x[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij] = np.zeros((50,))\n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d213c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#form the matrix from input data\n",
    "\n",
    "x_train_embedded_matrix = embedding_output(x_train)\n",
    "x_test_embedded_matrix = embedding_output(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a6d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_embedded_matrix.shape, x_test_embedded_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b3e4fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#convert y to one hot\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83031e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5) (56, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7c075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda577fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape = (10, 50)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c454eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelstack = Sequential()\n",
    "modelstack.add(LSTM(64, input_shape = (10, 50), return_sequences = True))\n",
    "modelstack.add(Dropout(0.5))\n",
    "modelstack.add(LSTM(64, return_sequences = False))\n",
    "modelstack.add(Dropout(0.5))\n",
    "modelstack.add(Dense(5))\n",
    "modelstack.add(Activation('softmax'))\n",
    "\n",
    "modelstack.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "modelstack.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f37b5919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8952 - val_loss: 1.1776 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.17761, saving model to best_model.h5\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.1840 - accuracy: 0.9524 - val_loss: 1.0371 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.17761 to 1.03707, saving model to best_model.h5\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 200us/step - loss: 0.2068 - accuracy: 0.9429 - val_loss: 1.0828 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.03707\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 217us/step - loss: 0.2232 - accuracy: 0.9429 - val_loss: 1.1855 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.03707\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.1773 - accuracy: 0.9524 - val_loss: 1.3830 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.03707\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.1844 - accuracy: 0.9524 - val_loss: 1.2338 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.03707\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.1570 - accuracy: 0.9619 - val_loss: 1.0760 - val_accuracy: 0.5926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\anaconda3\\envs\\gpu1\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 1.03707\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.1328 - accuracy: 0.9619 - val_loss: 1.0376 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.03707\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.1324 - accuracy: 0.9619 - val_loss: 1.0932 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.03707\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.1012 - accuracy: 0.9810 - val_loss: 1.1855 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.03707\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.1202 - accuracy: 0.9714 - val_loss: 1.2318 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.03707\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 257us/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 1.3041 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.03707\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.1062 - accuracy: 0.9714 - val_loss: 1.2801 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.03707\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0680 - accuracy: 0.9905 - val_loss: 1.2999 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.03707\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0809 - accuracy: 0.9810 - val_loss: 1.2217 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.03707\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0747 - accuracy: 0.9905 - val_loss: 1.1301 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.03707\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0677 - accuracy: 0.9905 - val_loss: 1.0754 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.03707\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 253us/step - loss: 0.0720 - accuracy: 0.9905 - val_loss: 1.0421 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.03707\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0723 - accuracy: 0.9905 - val_loss: 1.1073 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.03707\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0684 - accuracy: 0.9905 - val_loss: 1.0964 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.03707\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.03707\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 296us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 1.2716 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.03707\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 1.3684 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.03707\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0723 - accuracy: 0.9905 - val_loss: 1.4195 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.03707\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0503 - accuracy: 0.9905 - val_loss: 1.2212 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.03707\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 257us/step - loss: 0.0503 - accuracy: 0.9905 - val_loss: 1.1539 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.03707\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.1341 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.03707\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 302us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.1796 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.03707\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.03707\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.1517 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.03707\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.03707\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.2944 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.03707\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.4505 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.03707\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 287us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.3290 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.03707\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.2308 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.03707\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.1811 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.03707\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.1622 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.03707\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.03707\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 269us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.03707\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.2392 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.03707\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.03707\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.03707\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.4211 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.03707\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.4321 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.03707\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.4361 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.03707\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.03707\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 295us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.03707\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.03707\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 285us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4199 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.03707\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.4535 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.03707\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.03707\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 323us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.5468 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.03707\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.5147 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.03707\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.6439 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.03707\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 246us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.7603 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.03707\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.03707\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 240us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.03707\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.5460 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.03707\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.5545 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.03707\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.5138 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.03707\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.5086 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.03707\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.5550 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.03707\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 226us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6399 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.03707\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 244us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.6731 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.03707\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.6861 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.03707\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 238us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.6874 - val_accuracy: 0.4815\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.03707\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 234us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.6353 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.03707\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5731 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.03707\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 258us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5354 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.03707\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5149 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.03707\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 242us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.5244 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.03707\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.5300 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.03707\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 236us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.03707\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.03707\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 243us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.03707\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 234us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.6415 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.03707\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 236us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.03707\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 241us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.8199 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.03707\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 234us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.8927 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.03707\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.03707\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 232us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.9328 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.03707\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 235us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.9169 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.03707\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.8704 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.03707\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.8201 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.03707\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.8003 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.03707\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.03707\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 314us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7797 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.03707\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7732 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.03707\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 290us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.03707\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 285us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7860 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.03707\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.8238 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.03707\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 289us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.8707 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.03707\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 297us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9236 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.03707\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.9646 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.03707\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 281us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.9935 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.03707\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 295us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.9172 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.03707\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.03707\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 262us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.7252 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.03707\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 231us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.03707\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.7452 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.03707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27b7e68ae48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor = 'val_loss', verbose = True, save_best_only = True)\n",
    "earlystop = EarlyStopping(monitor = 'val_acc', patience = 5)\n",
    "\n",
    "model.fit(x_train_embedded_matrix, y_train, epochs = 100, batch_size= 64, shuffle = True, validation_split = 0.2, callbacks = [checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e72c8c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 0.3353 - accuracy: 0.8952 - val_loss: 1.0385 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03850, saving model to best_model_stack.h5\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 335us/step - loss: 0.2855 - accuracy: 0.9238 - val_loss: 1.0612 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03850\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.2304 - accuracy: 0.9429 - val_loss: 0.9597 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03850 to 0.95968, saving model to best_model_stack.h5\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.2639 - accuracy: 0.9238 - val_loss: 0.9816 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.95968\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 358us/step - loss: 0.2294 - accuracy: 0.9429 - val_loss: 0.9928 - val_accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rahul\\anaconda3\\envs\\gpu1\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.95968\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 359us/step - loss: 0.2211 - accuracy: 0.9524 - val_loss: 1.0501 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.95968\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 371us/step - loss: 0.2030 - accuracy: 0.9429 - val_loss: 1.1912 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.95968\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 381us/step - loss: 0.2006 - accuracy: 0.9524 - val_loss: 1.3491 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.95968\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 465us/step - loss: 0.1683 - accuracy: 0.9619 - val_loss: 1.1695 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.95968\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 465us/step - loss: 0.2085 - accuracy: 0.9619 - val_loss: 1.1097 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.95968\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.1092 - accuracy: 0.9905 - val_loss: 1.0691 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.95968\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 475us/step - loss: 0.1702 - accuracy: 0.9714 - val_loss: 1.0683 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.95968\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 466us/step - loss: 0.1509 - accuracy: 0.9810 - val_loss: 1.0851 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.95968\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.1044 - accuracy: 0.9810 - val_loss: 1.1037 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.95968\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.1155 - accuracy: 0.9810 - val_loss: 1.2066 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.95968\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.1216 - accuracy: 0.9905 - val_loss: 1.2446 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.95968\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.1068 - accuracy: 0.9810 - val_loss: 1.2027 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.95968\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 425us/step - loss: 0.0764 - accuracy: 0.9905 - val_loss: 1.1421 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.95968\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 418us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.0936 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.95968\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 401us/step - loss: 0.0817 - accuracy: 0.9905 - val_loss: 1.1171 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.95968\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.1031 - accuracy: 0.9714 - val_loss: 1.1299 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.95968\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 425us/step - loss: 0.0739 - accuracy: 0.9810 - val_loss: 1.1777 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.95968\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 384us/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 1.3520 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.95968\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0976 - accuracy: 0.9810 - val_loss: 1.5015 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.95968\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 446us/step - loss: 0.0865 - accuracy: 0.9905 - val_loss: 1.6509 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.95968\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 494us/step - loss: 0.1048 - accuracy: 0.9619 - val_loss: 1.4905 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.95968\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 0.1064 - accuracy: 0.9714 - val_loss: 1.2520 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.95968\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 465us/step - loss: 0.1010 - accuracy: 0.9619 - val_loss: 1.1474 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.95968\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 1.3440 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.95968\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 1.2716 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.95968\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0681 - accuracy: 0.9905 - val_loss: 1.3812 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.95968\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 414us/step - loss: 0.1436 - accuracy: 0.9810 - val_loss: 1.3727 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.95968\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 403us/step - loss: 0.1153 - accuracy: 0.9714 - val_loss: 1.3115 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.95968\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 425us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.95968\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 399us/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 1.3108 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.95968\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 408us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 1.4818 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.95968\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 364us/step - loss: 0.0812 - accuracy: 0.9810 - val_loss: 1.4470 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.95968\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 398us/step - loss: 0.1415 - accuracy: 0.9714 - val_loss: 1.2962 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.95968\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 407us/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 1.2133 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.95968\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 369us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 1.3717 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.95968\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 1.3777 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.95968\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 407us/step - loss: 0.0928 - accuracy: 0.9905 - val_loss: 1.1348 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.95968\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 1.0935 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.95968\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 371us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.95968\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 1.1574 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.95968\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.95968\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 399us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.95968\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.3032 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.95968\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.2869 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.95968\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.95968\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2981 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.95968\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 394us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3638 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.95968\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.4162 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.95968\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.95968\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.95968\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 399us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.95968\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.95968\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.95968\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 1.2059 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.95968\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.95968\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 364us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3505 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.95968\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.95968\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 408us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.95968\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 401us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.7407\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.95968\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4545 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.95968\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.4954 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.95968\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 387us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.5271 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.95968\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.95968\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 372us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5216 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.95968\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5213 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.95968\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 338us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.5360 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.95968\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 345us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.95968\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5702 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.95968\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 345us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.95968\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 345us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5812 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.95968\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 373us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.5426 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.95968\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5128 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.95968\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 419us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.95968\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 391us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.5204 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.95968\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.5367 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.95968\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 0.0404 - accuracy: 0.9905 - val_loss: 1.5409 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.95968\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 0.0145 - accuracy: 0.9905 - val_loss: 1.5375 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.95968\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 368us/step - loss: 0.0169 - accuracy: 0.9905 - val_loss: 1.5402 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.95968\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.95968\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 379us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.95968\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 363us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.6067 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.95968\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 0.0138 - accuracy: 0.9905 - val_loss: 1.6216 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.95968\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 370us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.6420 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.95968\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 370us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.6375 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.95968\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 441us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.95968\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 463us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6009 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.95968\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 408us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5864 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.95968\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 389us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.95968\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 396us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.95968\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 400us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.5498 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.95968\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 402us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5595 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.95968\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 362us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5715 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.95968\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 349us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.95968\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5903 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.95968\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 388us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.95968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27c79bd30f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model_stack.h5\", monitor = 'val_loss', verbose = True, save_best_only = True)\n",
    "earlystop = EarlyStopping(monitor = 'val_acc', patience = 5)\n",
    "\n",
    "modelstack.fit(x_train_embedded_matrix, y_train, epochs = 100, batch_size= 64, shuffle = True, validation_split = 0.2, callbacks = [checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "979d0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")\n",
    "modelstack.load_weights(\"best_model_stack.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03c6dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x_test_embedded_matrix)\n",
    "predstack = modelstack.predict_classes(x_test_embedded_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "633a6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 160us/step\n",
      "normal model gives -   68.0\n",
      "56/56 [==============================] - 0s 213us/step\n",
      "stacked model gives -   56.99999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc = model.evaluate(x_test_embedded_matrix, y_test)\n",
    "print('normal model gives -  ', round(acc[1],2) *100)\n",
    "\n",
    "accstack = modelstack.evaluate(x_test_embedded_matrix, y_test)\n",
    "print('stacked model gives -  ', round(accstack[1], 2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21be1132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 0, 2, 2, 3, 2, 1, 2, 1, 2, 0, 3, 1, 3, 2, 2, 3, 3, 0, 0,\n",
       "       4, 2, 3, 3, 1, 0, 1, 2, 0, 1, 3, 2, 3, 1, 2, 4, 1, 0, 1, 0, 2, 0,\n",
       "       2, 0, 3, 2, 3, 1, 3, 0, 3, 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45bd82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòû\n",
      "üòû\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "üòÉ\n",
      "üòû\n",
      "üòÉ\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "‚öæ\n",
      "üòû\n",
      "üòÉ\n",
      "üòÉ\n",
      "üòû\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üç¥\n",
      "üòÉ\n",
      "üòû\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòû\n",
      "üòÉ\n",
      "üòû\n",
      "‚öæ\n",
      "üòÉ\n",
      "üç¥\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üòÉ\n",
      "üòû\n",
      "‚öæ\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 89\n"
     ]
    }
   ],
   "source": [
    "for i in pred:\n",
    "    print(emoji.emojize(emoji_dictionary[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e95d1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòû\n",
      "üòû\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "üòÉ\n",
      "üòû\n",
      "üòÉ\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "‚öæ\n",
      "üòû\n",
      "üòÉ\n",
      "üòÉ\n",
      "üòû\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üç¥\n",
      "üòÉ\n",
      "üòû\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòû\n",
      "üòÉ\n",
      "üòû\n",
      "‚öæ\n",
      "üòÉ\n",
      "üç¥\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üòÉ\n",
      "üòû\n",
      "‚öæ\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "üòû\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "with open('emojiy_y_test.csv') as f:\n",
    "    y_t = f.read().split()\n",
    "for i in pred:\n",
    "    print(emoji.emojize(emoji_dictionary[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c13f884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [[' '.join(i)] for i in x_test]\n",
    "for idx in range(len(sent)):\n",
    "    sent[idx][0] = sent[idx][0].replace('\\\\t', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d530d3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence\n",
      "actual\n",
      "predicted\n",
      "I want to eat\n",
      "üç¥\n",
      "üòû\n",
      "he did not answer\n",
      "üòû\n",
      "üòû\n",
      "he got a very nice raise\n",
      "üòÉ\n",
      "üòÉ\n",
      "she got me a nice present\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "ha ha ha it was so funny\n",
      "üòÉ\n",
      "üòÉ\n",
      "he is a good friend\n",
      "üòÉ\n",
      "üòÉ\n",
      "I am upset\n",
      "üòû\n",
      "üòû\n",
      "We had such a lovely dinner tonight\n",
      "üòÉ\n",
      "üòÉ\n",
      "where is the food\n",
      "üç¥\n",
      "‚öæ\n",
      "Stop making this joke ha ha ha\n",
      "üòÉ\n",
      "üòÉ\n",
      "where is the ball\n",
      "‚öæ\n",
      "‚öæ\n",
      "work is hard\n",
      "üòû\n",
      "üòÉ\n",
      "This girl is messing with me\n",
      "üòû\n",
      "‚ù§Ô∏è\n",
      "are you serious\n",
      "üòû\n",
      "üòû\n",
      "Let us go play baseball\n",
      "‚öæ\n",
      "‚öæ\n",
      "This stupid grader is not working \n",
      "üòû\n",
      "üòû\n",
      "work is horrible\n",
      "üòû\n",
      "üòÉ\n",
      "Congratulation for having a baby\n",
      "üòÉ\n",
      "üòÉ\n",
      "stop pissing me off\n",
      "üòû\n",
      "üòû\n",
      "any suggestions for dinner\n",
      "üç¥\n",
      "üòû\n",
      "I love taking breaks\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you brighten my day\n",
      "üòÉ\n",
      "üòû\n",
      "I boiled rice\n",
      "üç¥\n",
      "üç¥\n",
      "she is a bully\n",
      "üòû\n",
      "üòÉ\n",
      "Why are you feeling bad\n",
      "üòû\n",
      "üòû\n",
      "I am upset\n",
      "üòû\n",
      "üòû\n",
      "give me the ball\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "My grandmother is the love of my life\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoy your game\n",
      "‚öæ\n",
      "‚öæ\n",
      "valentine day is near\n",
      "üòÉ\n",
      "üòÉ\n",
      "I miss you so much\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "throw the ball\n",
      "‚öæ\n",
      "‚öæ\n",
      "My life is so boring\n",
      "üòû\n",
      "üòû\n",
      "she said yes\n",
      "üòÉ\n",
      "üòÉ\n",
      "will you be my valentine\n",
      "üòÉ\n",
      "üòû\n",
      "he can pitch really well\n",
      "‚öæ\n",
      "‚öæ\n",
      "dance with me\n",
      "üòÉ\n",
      "üòÉ\n",
      "I am hungry\n",
      "üç¥\n",
      "üç¥\n",
      "See you at the restaurant\n",
      "üç¥\n",
      "‚öæ\n",
      "I like to laugh\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "I will run\n",
      "‚öæ\n",
      "‚öæ\n",
      "I like your jacket \n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "i miss her\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "what is your favorite baseball game\n",
      "‚öæ\n",
      "‚ù§Ô∏è\n",
      "Good job\n",
      "üòÉ\n",
      "üòÉ\n",
      "I love you to the stars and back\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "What you did was awesome\n",
      "üòÉ\n",
      "üòû\n",
      "ha ha ha lol\n",
      "üòÉ\n",
      "üòÉ\n",
      "I do not want to joke\n",
      "üòû\n",
      "üòû\n",
      "go away\n",
      "üòû\n",
      "‚öæ\n",
      "yesterday we lost again\n",
      "üòû\n",
      "üòû\n",
      "family is all I have\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you are failing this exercise\n",
      "üòû\n",
      "üòû\n",
      "Good joke\n",
      "üòÉ\n",
      "üòÉ\n",
      "You deserve this nice prize\n",
      "üòÉ\n",
      "‚ù§Ô∏è\n",
      "I did not have breakfast\n",
      "üç¥\n",
      "‚ù§Ô∏è\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence\")\n",
    "print(\"actual\")\n",
    "print(\"predicted\")\n",
    "for idx,[line] in enumerate(sent):\n",
    "    print(line)\n",
    "    print(emoji.emojize(emoji_dictionary[y_t[idx]]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[idx])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5432e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
